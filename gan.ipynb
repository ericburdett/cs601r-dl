{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ner.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJeDc0cDa070NZCEJjo0S5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/cs601r-dl/blob/master/gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoyRxyga7yC",
        "colab_type": "text"
      },
      "source": [
        "# Conditional Handwriting GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mNs_BtsaykG",
        "colab_type": "code",
        "outputId": "981efb8e-ef3f-47d5-d3d8-ba3c4f68a047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "from PIL import Image, ImageOps\n",
        "import gc\n",
        "import pdb\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from matplotlib.pyplot import imshow\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"Request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9aDvlkQNOjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"drive/My Drive/datasets/iam.zip\" \"/content\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4xL9fP7NtkU",
        "colab_type": "code",
        "outputId": "b2553e4a-4706-46a3-88f0-96b7f53b9ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "!unzip -q iam.zip\n",
        "!rm iam.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "warning [iam.zip]:  76 extra bytes at beginning or within zipfile\n",
            "  (attempting to process anyway)\n",
            "error [iam.zip]:  reported length of central directory is\n",
            "  -76 bytes too long (Atari STZip zipfile?  J.H.Holm ZIPSPLIT 1.1\n",
            "  zipfile?).  Compensating...\n",
            "error:  expected central file header signature not found (file #95173).\n",
            "  (please check that you have transferred or created the zipfile in the\n",
            "  appropriate BINARY mode and that you have compiled UnZip properly)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO8JWMj_gKi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IamDataset(Dataset):\n",
        "  def __init__(self, label='category', img_size=64):\n",
        "    if not os.path.exists('/content/labels.csv'):\n",
        "      raise Exception('Iam dataset does not exist in /content/labels.csv')\n",
        "\n",
        "    self.img_size = img_size\n",
        "    self.path = '/content/images/'\n",
        "    self.df = pd.read_csv('/content/labels.csv', sep='\\t', header=None, names=['word', 'seg', 'transcription'])\n",
        "    self.df = self.df.drop(['seg'], axis=1)\n",
        "\n",
        "  def get_df(self):\n",
        "    return self.df\n",
        "\n",
        "  def tensor_image(self, path):\n",
        "    img = Image.open(path + '.png')\n",
        "    img = self.resize(img)\n",
        "    x = transforms.functional.to_tensor(img)\n",
        "\n",
        "    # Look into automatically resizing or adding padding to images\n",
        "    # With a GAN, we will likely need all the input images to be the same size\n",
        "\n",
        "    return x\n",
        "\n",
        "  def resize(self, img):\n",
        "    old_size = img.size\n",
        "    ratio = float(self.img_size) / max(old_size)\n",
        "    new_size = tuple([int(x * ratio) for x in old_size])\n",
        "\n",
        "    img = img.resize(new_size, Image.ANTIALIAS)\n",
        "\n",
        "    new_img = Image.new(\"L\", (self.img_size, self.img_size))\n",
        "    new_img.paste(img, ((self.img_size - new_size[0]) // 2,\n",
        "                        (self.img_size - new_size[1]) // 2))\n",
        "    \n",
        "    return new_img\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img = self.tensor_image('images/' + self.df['word'][index])\n",
        "\n",
        "    return img, self.df['transcription'][index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkQ8f_k4d55i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tensor_to_image(t):\n",
        "  return transforms.ToPILImage()(t).convert(\"L\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCjJNP6ci0TN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, conv=nn.Conv2d, stride=1, padding=1, kernel=3, activation=nn.LeakyReLU):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "\n",
        "    self.conv1 = conv(in_channels, out_channels, kernel_size=kernel, padding=padding, stride=stride)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    self.act1 = activation()\n",
        "    self.conv2 = conv(out_channels, out_channels, kernel_size=kernel, padding=padding, stride=stride)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    self.act2 = activation()\n",
        "    \n",
        "    if in_channels != out_channels:\n",
        "      self.needs_shortcut = True\n",
        "      self.conv_short = conv(in_channels, out_channels, kernel_size=kernel, padding=padding, stride=stride, bias=False)\n",
        "      self.bn_short = nn.BatchNorm2d(out_channels)\n",
        "      self.shortcut = nn.Sequential(\n",
        "        self.conv_short,\n",
        "        self.bn_short\n",
        "      )\n",
        " \n",
        "    else:\n",
        "      self.needs_shortcut = False\n",
        "  \n",
        "  def forward(self, x):\n",
        "    identity = x if not self.needs_shortcut else self.shortcut(x)\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.act1(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "    out = self.act2(out)\n",
        "\n",
        "    if identity.shape[2] != out.shape[2]:\n",
        "      identity = F.interpolate(identity, size=out.shape[2])\n",
        "\n",
        "    out += identity\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSx5saIa-BbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper function to initialize the weights using a normal distribution. \n",
        "# this was done in the original work (instead of xavier) and has been shown\n",
        "# to help GAN performance\n",
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNY5u_Jd1xs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator2(nn.Module):\n",
        "  def __init__(self, img, layers=8, in_channels=1, channels=200):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.channels = channels\n",
        "    self.height = img.shape[1]\n",
        "    self.width = img.shape[2]\n",
        "\n",
        "    layers = [ResidualBlock(channels, channels, conv=nn.Conv2d) for _ in range(layers)]\n",
        "    layers.insert(0, ResidualBlock(in_channels, channels, conv=nn.Conv2d))\n",
        "    self.blocks = nn.Sequential(*layers)\n",
        "\n",
        "    self.fc = nn.Linear(self.channels * self.height * self.width, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.blocks(x)\n",
        "    out = out.view(-1, self.channels * self.height * self.width)\n",
        "    out = self.fc(out)\n",
        "    out = self.sigmoid(out)\n",
        "    return out.squeeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URQSF1JjQypT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator2(nn.Module):\n",
        "  def __init__(self, img):\n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "      ResidualBlock(in_channels=100, out_channels=90, conv=nn.ConvTranspose2d, kernel=4, stride=1, padding=1),\n",
        "      ResidualBlock(in_channels=90, out_channels=80, conv=nn.ConvTranspose2d, kernel=4, stride=1, padding=1),\n",
        "      ResidualBlock(in_channels=80, out_channels=70, conv=nn.ConvTranspose2d, kernel=4, stride=1, padding=1),\n",
        "      ResidualBlock(in_channels=70, out_channels=60, conv=nn.ConvTranspose2d, kernel=4, stride=1, padding=1),\n",
        "      ResidualBlock(in_channels=60, out_channels=50, conv=nn.ConvTranspose2d, kernel=4, stride=1, padding=1),\n",
        "      ResidualBlock(in_channels=50, out_channels=40, conv=nn.ConvTranspose2d, kernel=4, stride=1, padding=1),\n",
        "      ResidualBlock(in_channels=40, out_channels=30, conv=nn.ConvTranspose2d, kernel=4, stride=1, padding=1),\n",
        "      ResidualBlock(in_channels=30, out_channels=1, conv=nn.ConvTranspose2d, kernel=4, stride=2, padding=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x671tP0M9M8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self, d=128):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, d, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
        "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
        "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
        "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
        "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
        "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
        "\n",
        "    # weight_init\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
        "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
        "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
        "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
        "        x = torch.sigmoid(self.conv5(x))\n",
        "\n",
        "        return x.squeeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky79x2yA-MFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self, d=128):\n",
        "        super().__init__()\n",
        "        self.deconv1 = nn.ConvTranspose2d(100, d*8, 4, 1, 0)\n",
        "        self.deconv1_bn = nn.BatchNorm2d(d*8)\n",
        "        self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
        "        self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
        "        self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
        "        self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
        "        self.deconv4 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
        "        self.deconv4_bn = nn.BatchNorm2d(d)\n",
        "        self.deconv5 = nn.ConvTranspose2d(d, 1, 4, 2, 1)\n",
        "\n",
        "    # weight_init\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.deconv1_bn(self.deconv1(x)))\n",
        "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
        "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
        "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
        "        x = torch.tanh(self.deconv5(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yru5sPB-QWo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "21d80cd6-f898-486e-eb33-445e47ed5a0f"
      },
      "source": [
        "g = Generator()\n",
        "z = torch.randn(1, 100, 1, 1)\n",
        "g(z).shape"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 64, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAAv73IY9N-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d400426a-c55f-48e2-d2e7-2c15aec9ac51"
      },
      "source": [
        "d = Discriminator()\n",
        "d.weight_init(0, .2)\n",
        "d(img.unsqueeze(0)).item()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.8072648749221116e-06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd2FoWoz9g5s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cc0f1410-47b7-4f3a-943e-194c5ae3f8de"
      },
      "source": [
        "d(img.unsqueeze(0)).item()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.8072648749221116e-06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBS-0Ikz-0Xp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d05105f3-4cf4-43ce-a4f7-ed25c6c1c587"
      },
      "source": [
        "parameter_count(d)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11033985"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JrjI5w0eD_J",
        "colab_type": "code",
        "outputId": "3f797ec5-4cc6-4943-d180-4fdd75d14ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "dataset = IamDataset()\n",
        "item = dataset[5009]\n",
        "img = item[0]\n",
        "label = item[1]\n",
        "imshow(tensor_to_image(img), cmap='gray')\n",
        "print(\"Label: \", label)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label:  agitation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMqFgF8mEgl0kEwp2kUwo2EUy8f8VXgHYbIs2NwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKuBFdKy3tZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parameter_count(model):\n",
        "  return sum(p.numel() for p in model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPDQAC43w23o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "  NUM_EPOCHS = 1\n",
        "  BATCH_SIZE = 20\n",
        "  RATIO = 4 # How many times will we train the discriminator for each time we train the generator \n",
        "\n",
        "  dataset = IamDataset()\n",
        "\n",
        "  generator = Generator().cuda()\n",
        "  discriminator = Discriminator().cuda()\n",
        "  print('\\nGenerator: ', parameter_count(generator))\n",
        "  print('Discriminator: ', parameter_count(discriminator))\n",
        "\n",
        "  data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "  gen_optimizer = torch.optim.Adam(params=generator.parameters(), lr=1e-4)\n",
        "  disc_optimizer = torch.optim.Adam(params=discriminator.parameters(), lr=1e-4)\n",
        "\n",
        "  disc_objective = nn.BCELoss()\n",
        "  gen_objective = nn.BCELoss()\n",
        "\n",
        "  d_losses = []\n",
        "  g_losses = []\n",
        "\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    loop = tqdm(total=len(data_loader), position=0, leave=False)\n",
        "\n",
        "    for batch, (real_images, real_transcriptions) in enumerate(data_loader):\n",
        "      real_images = real_images.cuda(async=True)\n",
        "\n",
        "      generator.zero_grad()\n",
        "      discriminator.zero_grad()\n",
        "\n",
        "      # Create labels for real/fake images\n",
        "      fake_labels = torch.zeros(BATCH_SIZE).cuda()\n",
        "      real_labels = torch.ones(BATCH_SIZE).cuda()\n",
        "\n",
        "      # Sample from latent vector\n",
        "      z = torch.randn(BATCH_SIZE, 100, 1, 1).cuda()\n",
        "      fake_images = generator(z)\n",
        " \n",
        "      # Train Generator\n",
        "\n",
        "      gen_optimizer.zero_grad()\n",
        "\n",
        "      fake_pred = discriminator(fake_images)\n",
        "      gen_loss = gen_objective(fake_pred, real_labels) # The generator should be trying to generate real images\n",
        "\n",
        "      g_losses.append(gen_loss.item())\n",
        "\n",
        "      gen_loss.backward()\n",
        "      gen_optimizer.step()\n",
        "\n",
        "      # Train Discriminator\n",
        "      if batch % RATIO == 0:\n",
        "        disc_optimizer.zero_grad()\n",
        "\n",
        "        fake_pred = discriminator(fake_images.detach()) # Detach so we aren't training the generator\n",
        "        real_pred = discriminator(real_images)\n",
        "\n",
        "        fake_loss = disc_objective(fake_pred, fake_labels)\n",
        "        real_loss = disc_objective(real_pred, real_labels)\n",
        "        disc_loss = fake_loss + real_loss\n",
        "\n",
        "        d_losses.append(disc_loss.item())\n",
        "\n",
        "        disc_loss.backward()\n",
        "        disc_optimizer.step()\n",
        "\n",
        "      loop.set_description('Discriminator Loss: {:.4f}, Generator Loss: {:.4f}, AvgDiscriminator Loss: {:.4f}, AvgGenerator Loss: {:.4f}'.format(\n",
        "          disc_loss.item(), gen_loss.item(), np.mean(d_losses), np.mean(g_losses)))\n",
        "      loop.update(1)\n",
        "  \n",
        "  return generator, d_losses, g_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ua-qnK8xKIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f939c1d-bd06-468f-aa3a-7f42656a40ab"
      },
      "source": [
        "try:\n",
        "  generator, d_losses, g_losses = train()\n",
        "except:\n",
        "  __ITB__()\n",
        "  gc.collect()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4759 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Generator:  12656257\n",
            "Discriminator:  11033985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Discriminator Loss: 0.0426, Generator Loss: 3.7699, AvgDiscriminator Loss: 0.0686, AvgGenerator Loss: 6.3010:  14%|█▍        | 664/4759 [00:38<03:55, 17.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)\n",
            "\u001b[0;32m<ipython-input-140-5775e1c3d52c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m     26\u001b[0m     \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_transcriptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mbatch\u001b[0m \u001b[0;34m= 663\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mreal_images\u001b[0m \u001b[0;34m= tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mreal_transcriptions\u001b[0m \u001b[0;34m= ('the', 'British', 'grow', 'Oral', 'research', 'on', 'outside', 'in', 'America', 'were', 'I', 'advice', 'obviously', 'ratures', 'harm', 'was', 'remember', 'the', 'that', 'on')\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36menumerate\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mdata_loader\u001b[0m \u001b[0;34m= <torch.utils.data.dataloader.DataLoader object at 0x7f83874d96a0>\u001b[0m\n",
            "\u001b[1;32m     29\u001b[0m       \u001b[0mreal_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self=<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object>)\u001b[0m\n",
            "\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mdata\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself._next_data\u001b[0m \u001b[0;34m= <bound method _MultiProcessingDataLoaderIter._next_data of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f83874d9518>>\u001b[0m\n",
            "\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self=<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object>)\u001b[0m\n",
            "\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mself._process_data\u001b[0m \u001b[0;34m= <bound method _MultiProcessingDataLoaderIter._process_data of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f83874d9518>>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mdata\u001b[0m \u001b[0;34m= <torch._utils.ExceptionWrapper object at 0x7f83804a63c8>\u001b[0m\n",
            "\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self=<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object>, data=<torch._utils.ExceptionWrapper object>)\u001b[0m\n",
            "\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mdata.reraise\u001b[0m \u001b[0;34m= <bound method ExceptionWrapper.reraise of <torch._utils.ExceptionWrapper object at 0x7f83804a63c8>>\u001b[0m\n",
            "\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self=<torch._utils.ExceptionWrapper object>)\u001b[0m\n",
            "\u001b[1;32m    392\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mself.exc_type\u001b[0m \u001b[0;34m= <class 'OSError'>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mmsg\u001b[0m \u001b[0;34m= 'Caught OSError in DataLoader worker process 0.\\nOriginal Traceback (most recent call last):\\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\\n    data = fetcher.fetch(index)\\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\\n    data = [self.dataset[idx] for idx in possibly_batched_index]\\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\\n    data = [self.dataset[idx] for idx in possibly_batched_index]\\n  File \"<ipython-input-2-5460d182bb74>\", line 38, in __getitem__\\n    img = self.tensor_image(\\'images/\\' + self.df[\\'word\\'][index])\\n  File \"<ipython-input-2-5460d182bb74>\", line 15, in tensor_image\\n    img = Image.open(path + \\'.png\\')\\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2818, in open\\n    raise IOError(\"cannot identify image file %r\" % (filename if filename else fp))\\nOSError: cannot identify image file \\'images/d06-060-06-04.png\\'\\n'\u001b[0m\n",
            "\n",
            "\u001b[0;31mOSError\u001b[0m: Caught OSError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"<ipython-input-2-5460d182bb74>\", line 38, in __getitem__\n",
            "    img = self.tensor_image('images/' + self.df['word'][index])\n",
            "  File \"<ipython-input-2-5460d182bb74>\", line 15, in tensor_image\n",
            "    img = Image.open(path + '.png')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2818, in open\n",
            "    raise IOError(\"cannot identify image file %r\" % (filename if filename else fp))\n",
            "OSError: cannot identify image file 'images/d06-060-06-04.png'\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo0nf8fUA0oc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "outputId": "391eca12-22ab-40fc-d075-05c0eff4fef2"
      },
      "source": [
        "!head images/d06-060-06-03.png -n 100"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-147-2eb5d571ec15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'head images/d06-060-06-03.png -n 100'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_monitor_process\u001b[0;34m(parent_pty, epoll, p, cmd, update_stdin_widget)\u001b[0m\n\u001b[1;32m    220\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poll_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_poll_process\u001b[0;34m(parent_pty, epoll, p, cmd, decoder, state)\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0moutput_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0mraw_contents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_PTY_READ_MAX_BYTES_FOR_TEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m       \u001b[0mdecoded_contents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX-ponCNrRqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e9a82e89-4079-4db3-d95b-46c9cebac52a"
      },
      "source": [
        "m = nn.Sigmoid()\n",
        "loss = nn.BCELoss()\n",
        "input = torch.randn(3, requires_grad=True)\n",
        "target = torch.empty(3).random_(2)\n",
        "output = loss(m(input), target)\n",
        "print(input)\n",
        "print(target)\n",
        "print(output)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.5993, -0.8127,  0.7118], requires_grad=True)\n",
            "tensor([1., 1., 1.])\n",
            "tensor(0.8721, grad_fn=<BinaryCrossEntropyBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}