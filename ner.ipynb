{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ner.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPs+KA5igxXPKye06fqwOvs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/cs601r-dl/blob/master/ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoyRxyga7yC",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition on Handwritten Documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mNs_BtsaykG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d701fc08-a990-4002-f4e0-43344017109d"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "from PIL import Image, ImageOps\n",
        "import gc\n",
        "import pdb\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from matplotlib.pyplot import imshow\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"Request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9aDvlkQNOjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"drive/My Drive/datasets/esposalles.zip\" \"/content\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4xL9fP7NtkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q esposalles.zip\n",
        "!rm esposalles.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO8JWMj_gKi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EsposallesDataset(Dataset):\n",
        "  def __init__(self, label='category', img_size=128):\n",
        "    if not os.path.exists('/content/labels.csv'):\n",
        "      raise Exception('Esposalles dataset does not exist in /content/labels.csv')\n",
        "\n",
        "    self.img_size = img_size\n",
        "    self.label = label\n",
        "    self.path = '/content/Images/'\n",
        "    self.labels_df = pd.read_csv('/content/labels.csv', sep='\\t', header=None, names=['word', 'category', 'person', 'transcription', 'page'])\n",
        "\n",
        "    unique_labels = self.labels_df[label].drop_duplicates().values\n",
        "\n",
        "    self.num_to_label = dict()\n",
        "    self.label_to_num = dict()\n",
        "\n",
        "\n",
        "    for index, label in zip(range(len(unique_labels)), unique_labels):\n",
        "      self.num_to_label[index] = label\n",
        "      self.label_to_num[label] = index\n",
        "\n",
        "  def dicts(self):\n",
        "    return self.num_to_label, self.label_to_num\n",
        "  \n",
        "  def num_labels(self):\n",
        "    return len(self.num_to_label)\n",
        "\n",
        "  def resize(self, img):\n",
        "    old_size = img.size\n",
        "    ratio = float(self.img_size)/max(old_size)\n",
        "    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "\n",
        "    img = img.resize(new_size, Image.ANTIALIAS)\n",
        "\n",
        "    new_img = Image.new(\"RGB\", (self.img_size, self.img_size))\n",
        "    new_img.paste(img, ((self.img_size-new_size[0])//2,\n",
        "                        (self.img_size-new_size[1])//2))\n",
        "    \n",
        "    return new_img\n",
        "\n",
        "  def df(self):\n",
        "    return self.labels_df\n",
        "\n",
        "  def open_image(self, path):\n",
        "    img = Image.open(path + '.png')\n",
        "    img = self.resize(img)\n",
        "    x = transforms.functional.to_tensor(img)\n",
        "    # x = x.view(-1, self.img_size ** 2) # Shape the image tensor in a way that can be consumable by the GRU\n",
        "\n",
        "    return x\n",
        "\n",
        "  def __getitem__(self, index):    \n",
        "    pages = self.labels_df[self.labels_df['page'] == index]\n",
        "\n",
        "    imgs = []\n",
        "    labels = []\n",
        "\n",
        "    for _, row in pages.iterrows():\n",
        "      img = self.open_image(self.path + row['word'])\n",
        "      label_text = row[self.label]\n",
        "      label_num = self.label_to_num[label_text]\n",
        "\n",
        "      imgs.append(img)\n",
        "      labels.append(label_num)\n",
        "\n",
        "    return imgs, labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels_df['page'].drop_duplicates()) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vOsyMHSctcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channel_size, input_size, hidden_size, output_size, num_layers=1):\n",
        "    super(RNN, self).__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.hidden_channel_size = hidden_channel_size\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.conv1 = nn.Conv2d(self.in_channels, self.hidden_channel_size, kernel_size=3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(self.hidden_channel_size, self.hidden_channel_size, kernel_size=3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(self.hidden_channel_size, 1, kernel_size=3, padding=1)\n",
        "    self.gru = nn.GRU(input_size**2, hidden_size, num_layers)\n",
        "    self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, input_img, hidden):\n",
        "    # input_img = input_img.unsqueeze(0) # unsqueeze to comply with mini-batch for conv2d\n",
        "    out = self.conv1(input_img)\n",
        "    out = self.conv2(out)\n",
        "    out = self.conv3(out)\n",
        "    out = out.view(1, -1, self.input_size**2) # reshape to expected shape for gru\n",
        "    out, hidden = self.gru(out, hidden)\n",
        "    out = self.linear(out)\n",
        "\n",
        "    return out.view(-1), hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(self.num_layers, 1, self.hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz_0aaDcevwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93fd2504-cf9e-47f2-8960-a7ef2761fc26"
      },
      "source": [
        "NUM_EPOCHS = 1\n",
        "input_size = 64\n",
        "\n",
        "dataset = EsposallesDataset(img_size=input_size)\n",
        "data_loader = DataLoader(dataset,\n",
        "                          batch_size=1,\n",
        "                          num_workers=4,\n",
        "                          shuffle=False)\n",
        "\n",
        "\n",
        "hidden_size = 200\n",
        "hidden_channel_size = 50\n",
        "output_size = dataset.num_labels()\n",
        "num_layers = 3\n",
        "\n",
        "model = RNN(3, hidden_channel_size, input_size, hidden_size, output_size, num_layers=3)\n",
        "model = model.cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "objective = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loop = tqdm(total=len(data_loader), position=0, leave=True)\n",
        "\n",
        "  for batch, (x, y_truth) in enumerate(data_loader):\n",
        "    loss = 0\n",
        "    hidden = model.init_hidden()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    accs = []\n",
        "    losses = []\n",
        "\n",
        "    for word, label in zip(x, y_truth):\n",
        "      print(word.shape)\n",
        "      print(label.shape)\n",
        "      word, label = word.cuda(async=True), label.cuda(async=True)\n",
        "      pred, hidden = model(word, hidden)\n",
        "\n",
        "      acc = torch.eq(y_hat.argmax(), label)\n",
        "      ls = objective(pred, label)\n",
        "\n",
        "      accs.append(acc.item())\n",
        "      losses.append(ls.item())\n",
        "\n",
        "      loss += ls\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loop.set_description('Epoch:{}, Loss:{}, Acc:{}'.format(epoch, np.mean(losses), np.mean(accs)))\n",
        "    loop.update(1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/968 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}