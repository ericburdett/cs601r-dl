{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ner.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPROqMItkaAuYXQJnfJCXvb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/cs601r-dl/blob/master/ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoyRxyga7yC",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition on Handwritten Documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mNs_BtsaykG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc44dea0-227d-48e1-8fdc-bd2f636163df"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "from PIL import Image, ImageOps\n",
        "import gc\n",
        "import pdb\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from matplotlib.pyplot import imshow\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"Request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9aDvlkQNOjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"drive/My Drive/datasets/esposalles.zip\" \"/content\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4xL9fP7NtkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip esposalles.zip\n",
        "!rm esposalles.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO8JWMj_gKi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EsposallesDataset(Dataset):\n",
        "  def __init__(self, label='category', img_size=128):\n",
        "    if not os.path.exists('/content/labels.csv'):\n",
        "      raise Exception('Esposalles dataset does not exist in /content/labels.csv')\n",
        "\n",
        "    self.img_size = img_size\n",
        "    self.label = label\n",
        "    self.path = '/content/Images/'\n",
        "    self.labels_df = pd.read_csv('/content/labels.csv', sep='\\t', header=None, names=['word', 'category', 'person', 'transcription', 'page'])\n",
        "\n",
        "    unique_labels = self.labels_df[label].drop_duplicates().values\n",
        "\n",
        "    self.num_to_label = dict()\n",
        "    self.label_to_num = dict()\n",
        "\n",
        "\n",
        "    for index, label in zip(range(len(unique_labels)), unique_labels):\n",
        "      self.num_to_label[index] = label\n",
        "      self.label_to_num[label] = index\n",
        "\n",
        "  def dicts(self):\n",
        "    return self.num_to_label, self.label_to_num\n",
        "  \n",
        "  def num_labels(self):\n",
        "    return len(self.num_to_label)\n",
        "\n",
        "  def resize(self, img):\n",
        "    old_size = img.size\n",
        "    ratio = float(self.img_size)/max(old_size)\n",
        "    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "\n",
        "    img = img.resize(new_size, Image.ANTIALIAS)\n",
        "\n",
        "    new_img = Image.new(\"RGB\", (self.img_size, self.img_size))\n",
        "    new_img.paste(img, ((self.img_size-new_size[0])//2,\n",
        "                        (self.img_size-new_size[1])//2))\n",
        "    \n",
        "    return new_img\n",
        "\n",
        "  def df(self):\n",
        "    return self.labels_df\n",
        "\n",
        "  def open_image(self, path):\n",
        "    img = Image.open(path + '.png')\n",
        "    img = self.resize(img)\n",
        "    x = transforms.functional.to_tensor(img)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def __getitem__(self, index):    \n",
        "    pages = self.labels_df[self.labels_df['page'] == index]\n",
        "\n",
        "    imgs = []\n",
        "    labels = []\n",
        "\n",
        "    for _, row in pages.iterrows():\n",
        "      img = self.open_image(self.path + row['word'])\n",
        "      label_text = row[self.label]\n",
        "      label_num = self.label_to_num[label_text]\n",
        "\n",
        "      imgs.append(img)\n",
        "      labels.append(label_num)\n",
        "\n",
        "    return imgs, labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels_df['page'].drop_duplicates()) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vOsyMHSctcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.cnn1 = nn.Conv2d()\n",
        "    self.gru = nn.GRU(input_size, hidden_size, num_layers)\n",
        "    self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, input_img, hidden):\n",
        "    out = self.cnn1(input_img)\n",
        "    out, hidden = self.gru(input_img, hidden)\n",
        "    out = self.linear(out)\n",
        "\n",
        "    return out, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(self.num_layers, 1, self.hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDlCCfwuee2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNetEsposalles(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super(ResNetEsposalles, self).__init__()\n",
        "\n",
        "    self.model = torchvision.models.resnet152()\n",
        "\n",
        "    fc = nn.Linear(in_features=2048, out_features=num_classes)\n",
        "    fc.requires_grad=True\n",
        "    self.model.fc = fc\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsSyZGPKtphS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bb7456e-a14b-4341-b375-2173c2d179ca"
      },
      "source": [
        "batch_size = 5\n",
        "input_size = 10\n",
        "num_layers = 2\n",
        "hidden_size = 20\n",
        "seq_len = 3\n",
        "rnn = nn.GRU(input_size, hidden_size, num_layers)\n",
        "inp = torch.randn(batch_size, seq_len, input_size)\n",
        "h0 = torch.randn(num_layers, seq_len, hidden_size)\n",
        "output, hn = rnn(inp, h0)\n",
        "output.shape"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3, 20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R0_oYKkyf3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls Images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JhdYfJfvVJJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64138853-89e0-466b-a4f7-f3992400c1c6"
      },
      "source": [
        "# rnn = nn.GRU()\n",
        "\n",
        "conv = nn.Conv2d(3, 32, kernel_size=3)\n",
        "\n",
        "# dataset[0][0][0].unsqueeze(0).shape\n",
        "\n",
        "conv(dataset[0][0][0].unsqueeze(0)).shape"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 260, 344])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQVeW1aq18tB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed67526f-d037-4398-bf59-b93b2f6d3d92"
      },
      "source": [
        "dataset = EsposallesDataset(img_size=512)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 512, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz_0aaDcevwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "5db1e600-3a70-4787-b5c2-524b40ad39b0"
      },
      "source": [
        "dataset = EsposallesDataset()\n",
        "data_loader = DataLoader(train_dataset,\n",
        "                          batch_size=1,\n",
        "                          num_workers=4,\n",
        "                          shuffle=False)\n",
        "\n",
        "input_size = pass\n",
        "hidden_size = 200\n",
        "output_size = dataset.num_labels()\n",
        "num_layers = 3\n",
        "\n",
        "model = RNN(input_size, hidden_size, output_size, num_layers=3)\n",
        "model = model.cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "objective = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loop = tqdm(total=len(data_loader), position=0, leave=True)\n",
        "\n",
        "  for batch, (x, y_truth) in enumerate(data_loader):\n",
        "    x, y_truth = x.cuda(async=True), y_truth.cuda(async=True)\n",
        "    print(x)\n",
        "    print(y_truth)\n",
        "\n",
        "    loss = 0\n",
        "    hidden = model.init_hidden()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    accs = []\n",
        "    losses = []\n",
        "\n",
        "    for word, label in zip(x, y_truth):\n",
        "      optimizer.zero_grad()\n",
        "      pred, hidden = model(word, hidden))\n",
        "\n",
        "      acc = torch.eq(y_hat.argmax(), label)\n",
        "      ls = objective(pred, label)\n",
        "\n",
        "      accs.append(acc.item())\n",
        "      losses.append(ls.item())\n",
        "\n",
        "      loss += ls\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loop.set_description('Epoch:{}, Loss:{}, Acc:{}'.format(epoch, np.mean(losses), np.mean(accs)))\n",
        "    loop.update(1)\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-107-96144feee76b>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    input_size = pass\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}