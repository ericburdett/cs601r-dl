{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ner.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMEdqprnCbhRXoFBR7dtTL7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/cs601r-dl/blob/master/ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoyRxyga7yC",
        "colab_type": "text"
      },
      "source": [
        "# Named Entity Recognition on Handwritten Documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mNs_BtsaykG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8f9a727-e6ed-40ed-dcec-99399d1e2626"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "from PIL import Image, ImageOps\n",
        "import gc\n",
        "import pdb\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"Request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9aDvlkQNOjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"drive/My Drive/datasets/esposalles.zip\" \"/content\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4xL9fP7NtkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip esposalles.zip\n",
        "!rm esposalles.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmwN0wIARpw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls Images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO8JWMj_gKi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EsposallesDataset(Dataset):\n",
        "  def __init__(self, label='category'):\n",
        "    if not os.path.exists('/content/labels.csv'):\n",
        "      raise Exception('Esposalles dataset does not exist in /content/labels.csv')\n",
        "\n",
        "    self.label = label\n",
        "    self.path = '/content/Images/'\n",
        "    self.labels_df = pd.read_csv('/content/labels.csv', sep='\\t', header=None, names=['word', 'category', 'person', 'transcription', 'page'])\n",
        "\n",
        "  def df(self):\n",
        "    return self.labels_df\n",
        "\n",
        "  def open_image(self, path):\n",
        "    img = Image.open(path + '.png')\n",
        "    x = transforms.functional.to_tensor(img)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def __getitem__(self, index):    \n",
        "    pages = self.labels_df[self.labels_df['page'] == index]\n",
        "\n",
        "    imgs = []\n",
        "    labels = []\n",
        "\n",
        "    for _, row in pages.iterrows():\n",
        "      img = self.open_image(self.path + row['word'])\n",
        "      label = row[self.label]\n",
        "\n",
        "      imgs.append(img)\n",
        "      labels.append(label)\n",
        "\n",
        "    return imgs, labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vOsyMHSctcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.cnn1 = nn.Conv2d()\n",
        "    self.gru = nn.GRU(input_size, hidden_size, num_layers)\n",
        "    self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, input_img, hidden):\n",
        "    out, hidden = self.gru(input_img, hidden)\n",
        "    out = self.linear(out)\n",
        "\n",
        "    return out, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(self.num_layers, 1, self.hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz_0aaDcevwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = pass\n",
        "hidden_size = 200\n",
        "output_size = 5\n",
        "num_layers = 3\n",
        "\n",
        "model = RNN(input_size, hidden_size, output_size, num_layers=3)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "objective = nn.CrossEntropyLoss()\n",
        "\n",
        "dataset = IamDataset()\n",
        "data_loader = DataLoader(train_dataset,\n",
        "                          batch_size=1,\n",
        "                          num_workers=4,\n",
        "                          shuffle=False)\n",
        "\n",
        "def train():\n",
        "\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    loop = tqdm(total=len(data_loader), position=0, leave=True)\n",
        "\n",
        "    for batch, (x, y_truth) in enumerate(data_loader):\n",
        "      x, y_truth = x.cuda(async=True), y_truth.cuda(async=True)\n",
        "\n",
        "      loss = 0\n",
        "      hidden = model.init_hidden()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      accs = []\n",
        "      losses = []\n",
        "\n",
        "      for word, label in zip(x, y_truth):\n",
        "        optimizer.zero_grad()\n",
        "        pred, hidden = model(word, hidden))\n",
        "\n",
        "        acc = torch.eq(y_hat.argmax(), label)\n",
        "        ls = objective(pred, label)\n",
        "\n",
        "        accs.append(acc)\n",
        "        losses.append(ls)\n",
        "\n",
        "        loss += ls\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      loop.set_description('Epoch:{}, Loss:{}, Acc:{}'.format(epoch, loss, acc))\n",
        "      loop.update(1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}