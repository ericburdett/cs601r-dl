{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Lab1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericburdett/cs601r-dl/blob/master/DL_Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfXFi3BVHDT5",
        "colab_type": "text"
      },
      "source": [
        "# CS601R - Advanced Deep Learning\n",
        "\n",
        "## Lab 1 - Basic Classifier\n",
        "\n",
        "### Objective\n",
        "\n",
        "* Code a basic classifier in pytorch. Prepare a scaffold that will be used for experimentation in future labs.\n",
        "\n",
        "\n",
        "### Deliverable\n",
        "\n",
        "* For this lab, you will submit an ipython notebook via learningsuite. Your notebook must contain your classifier code, and should show various final statistics about it and its performance. You should plot your loss curve, a final confusion matrix, and you must clearly display the total parameter count of your network.\n",
        "\n",
        "### Grading Standards\n",
        "\n",
        "Your notebook will be graded on the following:\n",
        "\n",
        "* 45% Successfully created resnet\n",
        "* 5% Clearly display the total parameter count of your network\n",
        "* 20% Plotted loss curve\n",
        "* 20% Showed final confusion matrix\n",
        "* 10% Tidy and legible figures, including labeled axes where appropriate\n",
        "\n",
        "### Description\n",
        "\n",
        "For this lab, you will implement a basic pytorch image classifier on a reasonably large dataset.\n",
        "\n",
        "Details:\n",
        "\n",
        "Your classifier must be a 20 layer Resnet.\n",
        "\n",
        "The dataset is the Tiny Imagenet dataset. It has 200 classes, and 500 training images per class (for a total of 100k training images), and 10,000 testing images. (The dataset provides both labels and bounding boxes; you can ignore the boxes)\n",
        "\n",
        "You will probably want to use Google colab to host your notebook.\n",
        "\n",
        "For your loss curve, any reasonable visualization is acceptable.\n",
        "\n",
        "For your confusion matrix, you should display a 200×200 image, where each pixel i,j represents the number of times an image of class i was classified as class j.\n",
        "\n",
        "You will not be graded on any final accuracies. I think this is a pretty hard dataset, so I would not expect much better performance than 40% accuracy.\n",
        "\n",
        "You may use any code on the internet to help you, but all submitted code must be your own work.\n",
        "\n",
        "MAJOR HINT: we will be working with this classifier in future labs by adjusting its hyper parameters. In particular, you should make it easy to:\n",
        "\n",
        "* Change the activation function\n",
        "* Change whether or not you use BatchNorm\n",
        "* Change the learning rate schedule\n",
        "* Change the weight regularization\n",
        "* Change the weight initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tLQ6AzvJ5TC",
        "colab_type": "text"
      },
      "source": [
        "## Import & Create the Tiny-Imagenet Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8O60XWDIm2w",
        "colab_type": "code",
        "outputId": "eeb8713b-6b8c-47b5-9d1c-202005d29026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "from PIL import Image, ImageOps\n",
        "import gc\n",
        "import pdb\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"Request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXMDzOrGJcuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"drive/My Drive/datasets/tiny-imagenet-200.zip\" \"/content\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q09XFZ9YJozd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip tiny-imagenet-200.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2w2P_nlKGD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TinyImagenetDataset(Dataset):\n",
        "  def __init__(self, dataset_type='train'):\n",
        "    if not os.path.exists('/content/tiny-imagenet-200'):\n",
        "      raise Exception('Tiny-Imagenet dataset does not exist!')\n",
        "\n",
        "    if dataset_type == 'train':\n",
        "      self.dataset_folder = torchvision.datasets.ImageFolder('/content/tiny-imagenet-200/train',\n",
        "                                                             transform=transforms.Compose([transforms.ToTensor()]))\n",
        "    elif dataset_type == 'val':\n",
        "      self.dataset_folder = torchvision.datasets.ImageFolder('/content/tiny-imagenet-200/val',\n",
        "                                                             transform=transforms.Compose([transforms.ToTensor()]))\n",
        "    else:\n",
        "      self.dataset_folder = torchvision.datasets.ImageFolder('/content/tiny-imagenet-200/test',\n",
        "                                                             transform=transforms.Compose([transforms.ToTensor()]))\n",
        "    \n",
        "  def num_classes(self):\n",
        "    return len(self.dataset_folder.class_to_idx)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.dataset_folder[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfIE8Y_uP85c",
        "colab_type": "text"
      },
      "source": [
        "## Model Implementation - 20 Layer Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td9yv6vwQjrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, batch_norm=True, activation=nn.ReLU):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "\n",
        "    self.activation = activation\n",
        "\n",
        "    if batch_norm:\n",
        "      self.net = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        self.activation(),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.BatchNorm2d(out_channels)\n",
        "      )\n",
        "    else:\n",
        "      self.net = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        self.activation(),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
        "      )\n",
        "\n",
        "    if in_channels != out_channels:\n",
        "      self.needs_shortcut = True\n",
        "      self.shortcut = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels)\n",
        "      )\n",
        "    else:\n",
        "      self.needs_shortcut = False\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity = x if not self.needs_shortcut else self.shortcut(x)\n",
        "    out = self.net(x)\n",
        "    out += identity\n",
        "    final_activation = self.activation()\n",
        "\n",
        "    return final_activation(out)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1Igh7d8QAJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Resnet(nn.Module):\n",
        "  def __init__(self, dataset):\n",
        "    super(Resnet, self).__init__()\n",
        "\n",
        "    x, y = dataset[0]\n",
        "    in_channels, height, width = x.size()\n",
        "    cstart = 64\n",
        "\n",
        "    layers = []\n",
        "    layers.append(ResidualBlock(in_channels, cstart))\n",
        "    for i in range(4):\n",
        "      layers.append(ResidualBlock(cstart, cstart))\n",
        "    \n",
        "    layers.append(ResidualBlock(cstart, cstart*2))\n",
        "    for i in range(4):\n",
        "      layers.append(ResidualBlock(cstart*2, cstart*2))\n",
        "    \n",
        "    layers.append(ResidualBlock(cstart*2, cstart*4))\n",
        "    for i in range(4):\n",
        "      layers.append(ResidualBlock(cstart*4, cstart*4))\n",
        "\n",
        "    layers.append(ResidualBlock(cstart*4, cstart*8))\n",
        "    for i in range(4):\n",
        "      layers.append(ResidualBlock(cstart*8, cstart*8))\n",
        "\n",
        "    self.net = nn.Sequential(*layers)\n",
        "    self.fc1 = nn.Linear(cstart * 8 * height * width, dataset.num_classes())\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Residual Blocks\n",
        "    out = self.net(x)\n",
        "\n",
        "    # Flatten and narrow down to the number of classes\n",
        "    out = torch.flatten(out, 1)\n",
        "    out = self.fc1(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt0RBBAj4N_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PytorchResnet(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super(PytorchResnet, self).__init__()\n",
        "\n",
        "    self.model = torchvision.models.resnet152(pretrained=True)\n",
        "\n",
        "    fc = nn.Linear(in_features=2048, out_features=num_classes)\n",
        "    fc.requires_grad=True\n",
        "    self.model.fc = fc\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIVYe1JgZmvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b816b53f-8a57-45a9-f84f-ba4987dd5ced"
      },
      "source": [
        "def train():\n",
        "  NUM_EPOCHS = 1\n",
        "  BATCH_SIZE = 500\n",
        "\n",
        "  train_dataset = TinyImagenetDataset(dataset_type='train')\n",
        "  val_dataset = TinyImagenetDataset(dataset_type='val')\n",
        "\n",
        "  model = PytorchResnet(dataset.num_classes())\n",
        "  model = model.cuda()\n",
        "\n",
        "  objective = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            num_workers=4,\n",
        "                            shuffle=True)\n",
        "  val_loader = DataLoader(val_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=4,\n",
        "                          shuffle=True)\n",
        "  \n",
        "  train_losses = []\n",
        "  train_accs = []\n",
        "  val_losses = []\n",
        "  val_accs = []\n",
        "\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    loop = tqdm(total=len(train_loader), position=0, leave=True)\n",
        "\n",
        "    for batch, (x, y_truth) in enumerate(train_loader):\n",
        "      gc.collect()\n",
        "      x, y_truth = x.cuda(async=True), y_truth.cuda(async=True)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      y_hat = model(x)\n",
        "\n",
        "      acc = torch.eq(y_hat.argmax(1), y_truth.long()).float().mean()\n",
        "      loss = objective(y_hat, y_truth.long())\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      train_accs.append(acc.item())\n",
        "      train_losses.append(loss.item())\n",
        "\n",
        "      loop.set_description('Train - epoch:{}, loss:{:.4f}, acc:{:.4f}, avgloss:{:.4f}, avgacc:{:.4f}'.format(epoch, loss.item(), acc.item(), np.mean(train_losses), np.mean(train_accs)))\n",
        "      loop.update(1)\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "      val_single_loss = []\n",
        "      val_single_acc = []\n",
        "\n",
        "      model.eval()\n",
        "\n",
        "      for _, (val_x, val_y_truth) in enumerate(val_loader):\n",
        "        gc.collect()\n",
        "        val_x, val_y_truth = val_x.cuda(), val_y_truth.cuda()\n",
        "\n",
        "        val_y_hat = model(val_x)\n",
        "\n",
        "        val_acc = torch.eq(val_y_hat.argmax(1), val_y_truth.long()).float().mean()\n",
        "        val_loss = objective(val_y_hat, val_y_truth.long())\n",
        "\n",
        "        val_single_loss.append(val_loss.item())\n",
        "        val_single_acc.append(val_acc.item())\n",
        "\n",
        "      print('\\nValidation - epoch:{}, loss:{:.4f}, acc:{:.4f}'.format(epoch, np.mean(val_single_loss), np.mean(val_single_acc)))\n",
        "\n",
        "      val_accs.append(np.mean(val_single_acc))\n",
        "      val_losses.append(np.mean(val_single_loss))\n",
        "\n",
        "  loop.close()\n",
        "\n",
        "  return model, train_losses, train_accs, val_losses, val_accs\n",
        "\n",
        "try:\n",
        "  model, train_losses, train_accs, val_losses, val_accs = train()\n",
        "  gc.collect()\n",
        "except:\n",
        "  gc.collect()\n",
        "  __ITB__()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train - epoch:0, loss:5.3398, acc:0.0060, avgloss:5.3019, avgacc:0.0086: 100%|██████████| 200/200 [02:40<00:00,  1.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation - epoch:0, loss:5.1325, acc:0.0784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJtk7W0fFVme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abdcafde-b666-43f2-c9af-ea163c4a98ba"
      },
      "source": [
        "model.eval()\n",
        "model(dataset[50][0].unsqueeze(0).cuda()).argmax(1)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([30], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    }
  ]
}